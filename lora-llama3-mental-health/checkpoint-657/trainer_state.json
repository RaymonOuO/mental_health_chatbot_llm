{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.988610478359909,
  "eval_steps": 500,
  "global_step": 657,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04555808656036447,
      "grad_norm": 1.2574176788330078,
      "learning_rate": 0.00019726027397260273,
      "loss": 3.2599,
      "step": 10
    },
    {
      "epoch": 0.09111617312072894,
      "grad_norm": 1.1315312385559082,
      "learning_rate": 0.00019421613394216133,
      "loss": 3.0399,
      "step": 20
    },
    {
      "epoch": 0.1366742596810934,
      "grad_norm": 0.8704872131347656,
      "learning_rate": 0.00019117199391171992,
      "loss": 2.8565,
      "step": 30
    },
    {
      "epoch": 0.18223234624145787,
      "grad_norm": 0.750946581363678,
      "learning_rate": 0.00018812785388127855,
      "loss": 2.7277,
      "step": 40
    },
    {
      "epoch": 0.22779043280182232,
      "grad_norm": 0.6196469068527222,
      "learning_rate": 0.00018508371385083714,
      "loss": 2.6692,
      "step": 50
    },
    {
      "epoch": 0.2733485193621868,
      "grad_norm": 0.6555333137512207,
      "learning_rate": 0.00018203957382039574,
      "loss": 2.6859,
      "step": 60
    },
    {
      "epoch": 0.31890660592255127,
      "grad_norm": 0.7639433145523071,
      "learning_rate": 0.00017899543378995433,
      "loss": 2.656,
      "step": 70
    },
    {
      "epoch": 0.36446469248291574,
      "grad_norm": 0.6989105343818665,
      "learning_rate": 0.00017595129375951293,
      "loss": 2.6787,
      "step": 80
    },
    {
      "epoch": 0.41002277904328016,
      "grad_norm": 0.8526430130004883,
      "learning_rate": 0.00017290715372907155,
      "loss": 2.6167,
      "step": 90
    },
    {
      "epoch": 0.45558086560364464,
      "grad_norm": 0.6963557600975037,
      "learning_rate": 0.00016986301369863014,
      "loss": 2.6637,
      "step": 100
    },
    {
      "epoch": 0.5011389521640092,
      "grad_norm": 0.6646066904067993,
      "learning_rate": 0.00016681887366818874,
      "loss": 2.6151,
      "step": 110
    },
    {
      "epoch": 0.5466970387243736,
      "grad_norm": 0.7061984539031982,
      "learning_rate": 0.00016377473363774733,
      "loss": 2.6159,
      "step": 120
    },
    {
      "epoch": 0.592255125284738,
      "grad_norm": 0.7501187920570374,
      "learning_rate": 0.00016073059360730593,
      "loss": 2.6039,
      "step": 130
    },
    {
      "epoch": 0.6378132118451025,
      "grad_norm": 0.7204825282096863,
      "learning_rate": 0.00015768645357686452,
      "loss": 2.6256,
      "step": 140
    },
    {
      "epoch": 0.683371298405467,
      "grad_norm": 0.6201105117797852,
      "learning_rate": 0.00015464231354642315,
      "loss": 2.6119,
      "step": 150
    },
    {
      "epoch": 0.7289293849658315,
      "grad_norm": 0.7924674153327942,
      "learning_rate": 0.00015159817351598174,
      "loss": 2.5974,
      "step": 160
    },
    {
      "epoch": 0.7744874715261959,
      "grad_norm": 0.6671382784843445,
      "learning_rate": 0.00014855403348554034,
      "loss": 2.5823,
      "step": 170
    },
    {
      "epoch": 0.8200455580865603,
      "grad_norm": 0.7702581882476807,
      "learning_rate": 0.00014550989345509893,
      "loss": 2.5788,
      "step": 180
    },
    {
      "epoch": 0.8656036446469249,
      "grad_norm": 0.6863124370574951,
      "learning_rate": 0.00014246575342465753,
      "loss": 2.586,
      "step": 190
    },
    {
      "epoch": 0.9111617312072893,
      "grad_norm": 0.6589699387550354,
      "learning_rate": 0.00013942161339421612,
      "loss": 2.5839,
      "step": 200
    },
    {
      "epoch": 0.9567198177676538,
      "grad_norm": 0.7016201615333557,
      "learning_rate": 0.00013637747336377474,
      "loss": 2.6049,
      "step": 210
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.141778826713562,
      "learning_rate": 0.00013333333333333334,
      "loss": 2.6608,
      "step": 220
    },
    {
      "epoch": 1.0455580865603644,
      "grad_norm": 0.6546414494514465,
      "learning_rate": 0.00013028919330289193,
      "loss": 2.5593,
      "step": 230
    },
    {
      "epoch": 1.0911161731207288,
      "grad_norm": 0.7892224192619324,
      "learning_rate": 0.00012724505327245053,
      "loss": 2.577,
      "step": 240
    },
    {
      "epoch": 1.1366742596810935,
      "grad_norm": 0.788676917552948,
      "learning_rate": 0.00012420091324200913,
      "loss": 2.5705,
      "step": 250
    },
    {
      "epoch": 1.182232346241458,
      "grad_norm": 0.7010644674301147,
      "learning_rate": 0.00012115677321156773,
      "loss": 2.5681,
      "step": 260
    },
    {
      "epoch": 1.2277904328018223,
      "grad_norm": 0.7253676056861877,
      "learning_rate": 0.00011811263318112633,
      "loss": 2.5971,
      "step": 270
    },
    {
      "epoch": 1.2733485193621867,
      "grad_norm": 0.6455751061439514,
      "learning_rate": 0.00011506849315068494,
      "loss": 2.5523,
      "step": 280
    },
    {
      "epoch": 1.3189066059225514,
      "grad_norm": 0.8505345582962036,
      "learning_rate": 0.00011202435312024353,
      "loss": 2.5461,
      "step": 290
    },
    {
      "epoch": 1.3644646924829158,
      "grad_norm": 0.7757461667060852,
      "learning_rate": 0.00010898021308980213,
      "loss": 2.5621,
      "step": 300
    },
    {
      "epoch": 1.4100227790432802,
      "grad_norm": 0.7773129940032959,
      "learning_rate": 0.00010593607305936074,
      "loss": 2.5419,
      "step": 310
    },
    {
      "epoch": 1.4555808656036446,
      "grad_norm": 0.6828312873840332,
      "learning_rate": 0.00010289193302891933,
      "loss": 2.5319,
      "step": 320
    },
    {
      "epoch": 1.501138952164009,
      "grad_norm": 0.8199964165687561,
      "learning_rate": 9.984779299847793e-05,
      "loss": 2.5879,
      "step": 330
    },
    {
      "epoch": 1.5466970387243735,
      "grad_norm": 0.7656840682029724,
      "learning_rate": 9.680365296803654e-05,
      "loss": 2.5015,
      "step": 340
    },
    {
      "epoch": 1.592255125284738,
      "grad_norm": 0.6987108588218689,
      "learning_rate": 9.375951293759513e-05,
      "loss": 2.5473,
      "step": 350
    },
    {
      "epoch": 1.6378132118451025,
      "grad_norm": 0.7306682467460632,
      "learning_rate": 9.071537290715373e-05,
      "loss": 2.5296,
      "step": 360
    },
    {
      "epoch": 1.683371298405467,
      "grad_norm": 0.776236891746521,
      "learning_rate": 8.767123287671233e-05,
      "loss": 2.5482,
      "step": 370
    },
    {
      "epoch": 1.7289293849658316,
      "grad_norm": 0.8109352588653564,
      "learning_rate": 8.462709284627093e-05,
      "loss": 2.5849,
      "step": 380
    },
    {
      "epoch": 1.774487471526196,
      "grad_norm": 0.7449835538864136,
      "learning_rate": 8.158295281582952e-05,
      "loss": 2.5591,
      "step": 390
    },
    {
      "epoch": 1.8200455580865604,
      "grad_norm": 0.8696156144142151,
      "learning_rate": 7.853881278538813e-05,
      "loss": 2.5493,
      "step": 400
    },
    {
      "epoch": 1.8656036446469249,
      "grad_norm": 0.7727786302566528,
      "learning_rate": 7.549467275494673e-05,
      "loss": 2.5781,
      "step": 410
    },
    {
      "epoch": 1.9111617312072893,
      "grad_norm": 0.7931428551673889,
      "learning_rate": 7.245053272450532e-05,
      "loss": 2.4833,
      "step": 420
    },
    {
      "epoch": 1.9567198177676537,
      "grad_norm": 0.8097074031829834,
      "learning_rate": 6.940639269406393e-05,
      "loss": 2.516,
      "step": 430
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.2832460403442383,
      "learning_rate": 6.636225266362253e-05,
      "loss": 2.5492,
      "step": 440
    },
    {
      "epoch": 2.0455580865603644,
      "grad_norm": 0.8313997983932495,
      "learning_rate": 6.331811263318112e-05,
      "loss": 2.495,
      "step": 450
    },
    {
      "epoch": 2.091116173120729,
      "grad_norm": 0.7900161147117615,
      "learning_rate": 6.0273972602739724e-05,
      "loss": 2.5143,
      "step": 460
    },
    {
      "epoch": 2.1366742596810933,
      "grad_norm": 1.014686107635498,
      "learning_rate": 5.7229832572298325e-05,
      "loss": 2.5372,
      "step": 470
    },
    {
      "epoch": 2.1822323462414577,
      "grad_norm": 0.8438339233398438,
      "learning_rate": 5.418569254185693e-05,
      "loss": 2.5147,
      "step": 480
    },
    {
      "epoch": 2.2277904328018225,
      "grad_norm": 1.0276542901992798,
      "learning_rate": 5.114155251141552e-05,
      "loss": 2.4998,
      "step": 490
    },
    {
      "epoch": 2.273348519362187,
      "grad_norm": 0.7591426372528076,
      "learning_rate": 4.8097412480974124e-05,
      "loss": 2.4915,
      "step": 500
    },
    {
      "epoch": 2.3189066059225514,
      "grad_norm": 0.9413058161735535,
      "learning_rate": 4.5053272450532726e-05,
      "loss": 2.5225,
      "step": 510
    },
    {
      "epoch": 2.364464692482916,
      "grad_norm": 0.8555136322975159,
      "learning_rate": 4.200913242009132e-05,
      "loss": 2.5063,
      "step": 520
    },
    {
      "epoch": 2.41002277904328,
      "grad_norm": 0.845079243183136,
      "learning_rate": 3.896499238964992e-05,
      "loss": 2.5248,
      "step": 530
    },
    {
      "epoch": 2.4555808656036446,
      "grad_norm": 0.7489970326423645,
      "learning_rate": 3.5920852359208525e-05,
      "loss": 2.5037,
      "step": 540
    },
    {
      "epoch": 2.501138952164009,
      "grad_norm": 0.7917042970657349,
      "learning_rate": 3.287671232876712e-05,
      "loss": 2.5342,
      "step": 550
    },
    {
      "epoch": 2.5466970387243735,
      "grad_norm": 0.7691860795021057,
      "learning_rate": 2.9832572298325722e-05,
      "loss": 2.5452,
      "step": 560
    },
    {
      "epoch": 2.592255125284738,
      "grad_norm": 0.8661923408508301,
      "learning_rate": 2.6788432267884324e-05,
      "loss": 2.4955,
      "step": 570
    },
    {
      "epoch": 2.6378132118451028,
      "grad_norm": 0.8167533278465271,
      "learning_rate": 2.3744292237442922e-05,
      "loss": 2.5097,
      "step": 580
    },
    {
      "epoch": 2.6833712984054667,
      "grad_norm": 0.9265556335449219,
      "learning_rate": 2.070015220700152e-05,
      "loss": 2.5093,
      "step": 590
    },
    {
      "epoch": 2.7289293849658316,
      "grad_norm": 0.8984252214431763,
      "learning_rate": 1.7656012176560123e-05,
      "loss": 2.4967,
      "step": 600
    },
    {
      "epoch": 2.774487471526196,
      "grad_norm": 0.8558117747306824,
      "learning_rate": 1.4611872146118721e-05,
      "loss": 2.5297,
      "step": 610
    },
    {
      "epoch": 2.8200455580865604,
      "grad_norm": 0.828018069267273,
      "learning_rate": 1.1567732115677321e-05,
      "loss": 2.5219,
      "step": 620
    },
    {
      "epoch": 2.865603644646925,
      "grad_norm": 0.8461963534355164,
      "learning_rate": 8.523592085235922e-06,
      "loss": 2.5291,
      "step": 630
    },
    {
      "epoch": 2.9111617312072893,
      "grad_norm": 0.943408191204071,
      "learning_rate": 5.479452054794521e-06,
      "loss": 2.5165,
      "step": 640
    },
    {
      "epoch": 2.9567198177676537,
      "grad_norm": 0.9538487195968628,
      "learning_rate": 2.43531202435312e-06,
      "loss": 2.5107,
      "step": 650
    }
  ],
  "logging_steps": 10,
  "max_steps": 657,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.140531358007296e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
